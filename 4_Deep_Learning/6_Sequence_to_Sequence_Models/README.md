# Sequence-to-Sequence Models

This section covers Sequence-to-Sequence (Seq2Seq) models, which are a class of deep learning models used for tasks where the input and output are both sequences, but their lengths can differ. Key applications include machine translation, text summarization, and chatbots.

For a detailed understanding of Seq2Seq concepts, refer to [Seq2Seq Concepts](seq2seq_concepts.md).